{
  "dataset": "sst2",
  "timestamp": "2025-11-06T22:27:29.785384",
  "config": {
    "num_labels": 2,
    "train_samples": 1000,
    "val_samples": 872,
    "batch_size": 128,
    "use_tpu": true,
    "model_dtype": "bfloat16"
  },
  "arms": {
    "baseline": {
      "arm": "baseline",
      "val_accuracy": 0.6777522935779816,
      "val_macro_f1": 0.6682408500590319,
      "val_loss": 0.6311383928571429,
      "epochs_run": 0,
      "optimizer_steps": 0,
      "tokens_processed": 0,
      "wall_time_minutes": 1.194546393553416,
      "notes": "Pretrained baseline (frozen backbone + 1-epoch head)"
    },
    "influence": {
      "arm": "influence",
      "val_accuracy": 0.4896788990825688,
      "val_macro_f1": 0.0,
      "val_loss": 24.642857142857142,
      "epochs_run": 0,
      "optimizer_steps": 0,
      "tokens_processed": 0,
      "num_masked_params": 17959815,
      "mask_fraction": 0.05,
      "total_params": 494034560,
      "wall_time_minutes": 6.855368177096049,
      "notes": "Influence-based masking (5.0% params masked)"
    },
    "lora": {
      "arm": "lora",
      "val_accuracy": 0.8830275229357798,
      "val_macro_f1": 0.8907922912205567,
      "val_loss": 0.4321986607142857,
      "epochs_run": 5,
      "optimizer_steps": 40,
      "tokens_processed": 1280000,
      "lora_rank": 8,
      "lora_alpha": 16,
      "wall_time_minutes": 6.868667483329773,
      "notes": "LoRA (rank=8, alpha=16)"
    },
    "fullft": {
      "arm": "fullft",
      "val_accuracy": 0.8979357798165137,
      "val_macro_f1": 0.8996617812852311,
      "val_loss": 0.4174107142857143,
      "epochs_run": 5,
      "optimizer_steps": 40,
      "tokens_processed": 1280000,
      "wall_time_minutes": 6.25537383556366,
      "notes": "Full fine-tuning (entire model)"
    }
  }
}